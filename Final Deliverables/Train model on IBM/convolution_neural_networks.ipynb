{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUrEEFCwv20y",
        "outputId": "5b1cce84-058b-4b52-da30-3cac43c4eb4b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cells': [{'cell_type': 'code',\n",
              "   'execution_count': 3,\n",
              "   'metadata': {'id': '-4U2x7XApAPv'},\n",
              "   'outputs': [{'data': {'text/plain': [\"'/home/wsuser/work'\"]},\n",
              "     'execution_count': 3,\n",
              "     'metadata': {},\n",
              "     'output_type': 'execute_result'}],\n",
              "   'source': ['pwd']},\n",
              "  {'cell_type': 'code',\n",
              "   'execution_count': 7,\n",
              "   'metadata': {},\n",
              "   'outputs': [{'name': 'stdout',\n",
              "     'output_type': 'stream',\n",
              "     'text': ['Collecting keras==2.7.0\\n',\n",
              "      '  Downloading keras-2.7.0-py2.py3-none-any.whl (1.3 MB)\\n',\n",
              "      '\\x1b[K     |████████████████████████████████| 1.3 MB 22.6 MB/s eta 0:00:01\\n',\n",
              "      '\\x1b[?25hInstalling collected packages: keras\\n',\n",
              "      '  Attempting uninstall: keras\\n',\n",
              "      '    Found existing installation: keras 2.10.0\\n',\n",
              "      '    Uninstalling keras-2.10.0:\\n',\n",
              "      '      Successfully uninstalled keras-2.10.0\\n',\n",
              "      \"\\x1b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\\n\",\n",
              "      'tensorflow 2.10.0 requires keras<2.11,>=2.10.0, but you have keras 2.7.0 which is incompatible.\\n',\n",
              "      'tensorflow-text 2.7.3 requires tensorflow<2.8,>=2.7.0, but you have tensorflow 2.10.0 which is incompatible.\\n',\n",
              "      'autoai-ts-libs 1.1.9 requires tensorflow<2.8,>=2.7.0; python_version >= \"3.9\", but you have tensorflow 2.10.0 which is incompatible.\\x1b[0m\\n',\n",
              "      'Successfully installed keras-2.7.0\\n',\n",
              "      'Requirement already satisfied: tensorflow==2.10.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (2.10.0)\\n',\n",
              "      'Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.10.0) (1.42.0)\\n',\n",
              "      'Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.10.0) (3.3.0)\\n',\n",
              "      'Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.10.0) (1.3.0)\\n',\n",
              "      'Requirement already satisfied: numpy>=1.20 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.10.0) (1.20.3)\\n',\n",
              "      'Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.10.0) (1.6.3)\\n',\n",
              "      'Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.10.0) (0.4.0)\\n',\n",
              "      'Requirement already satisfied: setuptools in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.10.0) (58.0.4)\\n',\n",
              "      'Requirement already satisfied: tensorboard<2.11,>=2.10 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.10.0) (2.10.1)\\n',\n",
              "      'Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.10.0) (0.2.0)\\n',\n",
              "      'Requirement already satisfied: keras-preprocessing>=1.1.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.10.0) (1.1.2)\\n',\n",
              "      'Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.10.0) (4.1.1)\\n',\n",
              "      'Requirement already satisfied: flatbuffers>=2.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.10.0) (2.0)\\n',\n",
              "      'Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.10.0) (1.1.0)\\n',\n",
              "      'Requirement already satisfied: h5py>=2.9.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.10.0) (3.2.1)\\n',\n",
              "      'Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.10.0) (0.23.1)\\n',\n",
              "      'Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.10.0) (2.10.0)\\n',\n",
              "      'Requirement already satisfied: protobuf<3.20,>=3.9.2 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.10.0) (3.19.1)\\n',\n",
              "      'Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.10.0) (1.12.1)\\n',\n",
              "      'Collecting keras<2.11,>=2.10.0\\n',\n",
              "      '  Using cached keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\\n',\n",
              "      'Requirement already satisfied: six>=1.12.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.10.0) (1.15.0)\\n',\n",
              "      'Requirement already satisfied: libclang>=13.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.10.0) (14.0.6)\\n',\n",
              "      'Requirement already satisfied: packaging in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.10.0) (21.3)\\n',\n",
              "      'Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow==2.10.0) (0.37.0)\\n',\n",
              "      'Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.4.4)\\n',\n",
              "      'Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (1.6.0)\\n',\n",
              "      'Requirement already satisfied: markdown>=2.6.8 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.3.3)\\n',\n",
              "      'Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.6.1)\\n',\n",
              "      'Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.0.2)\\n',\n",
              "      'Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (1.23.0)\\n',\n",
              "      'Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.26.0)\\n',\n",
              "      'Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (4.7.2)\\n',\n",
              "      'Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (4.2.2)\\n',\n",
              "      'Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.2.8)\\n',\n",
              "      'Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (1.3.0)\\n',\n",
              "      'Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.4.8)\\n',\n",
              "      'Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (1.26.7)\\n',\n",
              "      'Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.0.4)\\n',\n",
              "      'Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.3)\\n',\n",
              "      'Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2022.9.24)\\n',\n",
              "      'Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.2.1)\\n',\n",
              "      'Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from packaging->tensorflow==2.10.0) (3.0.4)\\n',\n",
              "      'Installing collected packages: keras\\n',\n",
              "      '  Attempting uninstall: keras\\n',\n",
              "      '    Found existing installation: keras 2.7.0\\n',\n",
              "      '    Uninstalling keras-2.7.0:\\n',\n",
              "      '      Successfully uninstalled keras-2.7.0\\n',\n",
              "      \"\\x1b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\\n\",\n",
              "      'tensorflow-text 2.7.3 requires tensorflow<2.8,>=2.7.0, but you have tensorflow 2.10.0 which is incompatible.\\n',\n",
              "      'autoai-ts-libs 1.1.9 requires tensorflow<2.8,>=2.7.0; python_version >= \"3.9\", but you have tensorflow 2.10.0 which is incompatible.\\x1b[0m\\n',\n",
              "      'Successfully installed keras-2.10.0\\n']}],\n",
              "   'source': ['!pip install keras==2.7.0\\n',\n",
              "    '!pip install tensorflow==2.10.0']},\n",
              "  {'cell_type': 'code',\n",
              "   'execution_count': 8,\n",
              "   'metadata': {},\n",
              "   'outputs': [],\n",
              "   'source': ['#import keras libraries\\n',\n",
              "    'from keras.models import Sequential #api,se\\n',\n",
              "    'from keras.layers import Dense #add layers\\n',\n",
              "    'from keras.layers import Convolution2D #con\\n',\n",
              "    'from keras.layers import MaxPooling2D\\n',\n",
              "    'from keras.layers import Flatten']},\n",
              "  {'cell_type': 'code',\n",
              "   'execution_count': 9,\n",
              "   'metadata': {'id': 'GUqs8zuap0Ro'},\n",
              "   'outputs': [],\n",
              "   'source': ['#image preprocessing(or) image augmentation\\n',\n",
              "    'from keras.preprocessing.image import ImageDataGenerator']},\n",
              "  {'cell_type': 'code',\n",
              "   'execution_count': 10,\n",
              "   'metadata': {'id': 't44vJdxpqO67'},\n",
              "   'outputs': [],\n",
              "   'source': ['train_datagen = ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True,vertical_flip=True)\\n',\n",
              "    '#rescale => rescaling pixel value from 0 to 255 to 0 to 1\\n',\n",
              "    '#shear_range=> counter clock wise rotation(anti clock)']},\n",
              "  {'cell_type': 'code',\n",
              "   'execution_count': 11,\n",
              "   'metadata': {'id': 'bPtjB_31qZLl'},\n",
              "   'outputs': [],\n",
              "   'source': ['test_datagen = ImageDataGenerator(rescale=1./255)']},\n",
              "  {'cell_type': 'code',\n",
              "   'execution_count': 12,\n",
              "   'metadata': {},\n",
              "   'outputs': [],\n",
              "   'source': ['\\n',\n",
              "    'import os, types\\n',\n",
              "    'import pandas as pd\\n',\n",
              "    'from botocore.client import Config\\n',\n",
              "    'import ibm_boto3\\n',\n",
              "    '\\n',\n",
              "    'def __iter__(self): return 0\\n',\n",
              "    '\\n',\n",
              "    '# @hidden_cell\\n',\n",
              "    '# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\\n',\n",
              "    '# You might want to remove those credentials before you share the notebook.\\n',\n",
              "    \"cos_client = ibm_boto3.client(service_name='s3',\\n\",\n",
              "    \"    ibm_api_key_id='6L2of0JKTob3sCgpaW9F6IcVfD7HJNHrn9Owefk-q5wo',\\n\",\n",
              "    '    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\\n',\n",
              "    \"    config=Config(signature_version='oauth'),\\n\",\n",
              "    \"    endpoint_url='https://s3.private.us.cloud-object-storage.appdomain.cloud')\\n\",\n",
              "    '\\n',\n",
              "    \"bucket = 'imageclassification-donotdelete-pr-fleoxflx4ga1rw'\\n\",\n",
              "    \"object_key = 'Dataset-20221107T052301Z-001.zip'\\n\",\n",
              "    '\\n',\n",
              "    \"streaming_body_1 = cos_client.get_object(Bucket=bucket, Key=object_key)['Body']\\n\",\n",
              "    '\\n',\n",
              "    '# Your data file was loaded into a botocore.response.StreamingBody object.\\n',\n",
              "    '# Please read the documentation of ibm_boto3 and pandas to learn more about the possibilities to load the data.\\n',\n",
              "    '# ibm_boto3 documentation: https://ibm.github.io/ibm-cos-sdk-python/\\n',\n",
              "    '# pandas documentation: http://pandas.pydata.org/\\n']},\n",
              "  {'cell_type': 'code',\n",
              "   'execution_count': 13,\n",
              "   'metadata': {},\n",
              "   'outputs': [],\n",
              "   'source': ['from io import BytesIO\\n',\n",
              "    'import zipfile\\n',\n",
              "    \"unzip=zipfile.ZipFile(BytesIO(streaming_body_1.read()),'r')\\n\",\n",
              "    'file_paths=unzip.namelist()\\n',\n",
              "    'for path in file_paths:\\n',\n",
              "    '    unzip.extract(path)']},\n",
              "  {'cell_type': 'code',\n",
              "   'execution_count': 14,\n",
              "   'metadata': {},\n",
              "   'outputs': [{'name': 'stdout',\n",
              "     'output_type': 'stream',\n",
              "     'text': ['\\x1b[0m\\x1b[01;34mDataset\\x1b[0m/\\r\\n']}],\n",
              "   'source': ['ls']},\n",
              "  {'cell_type': 'code',\n",
              "   'execution_count': 15,\n",
              "   'metadata': {},\n",
              "   'outputs': [{'data': {'text/plain': [\"'/home/wsuser/work'\"]},\n",
              "     'execution_count': 15,\n",
              "     'metadata': {},\n",
              "     'output_type': 'execute_result'}],\n",
              "   'source': ['pwd']},\n",
              "  {'cell_type': 'code',\n",
              "   'execution_count': 16,\n",
              "   'metadata': {},\n",
              "   'outputs': [],\n",
              "   'source': ['import os \\n',\n",
              "    \"filenames = os.listdir('/home/wsuser/work/Dataset')\"]},\n",
              "  {'cell_type': 'code',\n",
              "   'execution_count': 17,\n",
              "   'metadata': {'colab': {'base_uri': 'https://localhost:8080/'},\n",
              "    'id': 'ltTuui5Kqdtp',\n",
              "    'outputId': '2f168c3f-c51e-4c92-dc28-3d4ea011d4da'},\n",
              "   'outputs': [{'name': 'stdout',\n",
              "     'output_type': 'stream',\n",
              "     'text': ['Found 4118 images belonging to 5 classes.\\n']}],\n",
              "   'source': ['x_train = train_datagen.flow_from_directory(\"/home/wsuser/work/Dataset/TRAIN_SET\",target_size=(64,64),batch_size=32,class_mode=\"categorical\")']},\n",
              "  {'cell_type': 'code',\n",
              "   'execution_count': 18,\n",
              "   'metadata': {'colab': {'base_uri': 'https://localhost:8080/'},\n",
              "    'id': 'U9WzDTJHuiAh',\n",
              "    'outputId': '87f6e98f-1cba-473a-b803-faa60d4eeb7d'},\n",
              "   'outputs': [{'name': 'stdout',\n",
              "     'output_type': 'stream',\n",
              "     'text': ['Found 929 images belonging to 5 classes.\\n']}],\n",
              "   'source': ['x_test = test_datagen.flow_from_directory(\"/home/wsuser/work/Dataset/TEST_SET\",target_size=(64,64),batch_size=32,class_mode=\"categorical\")']},\n",
              "  {'cell_type': 'code',\n",
              "   'execution_count': 19,\n",
              "   'metadata': {'colab': {'base_uri': 'https://localhost:8080/'},\n",
              "    'id': 'bApCdADGup8T',\n",
              "    'outputId': 'd57ab51e-f9c3-47b2-f19c-f25f10a7aec7'},\n",
              "   'outputs': [{'data': {'text/plain': [\"{'APPLES': 0, 'BANANA': 1, 'ORANGE': 2, 'PINEAPPLE': 3, 'WATERMELON': 4}\"]},\n",
              "     'execution_count': 19,\n",
              "     'metadata': {},\n",
              "     'output_type': 'execute_result'}],\n",
              "   'source': ['x_train.class_indices']},\n",
              "  {'cell_type': 'code',\n",
              "   'execution_count': 20,\n",
              "   'metadata': {'colab': {'base_uri': 'https://localhost:8080/'},\n",
              "    'id': '9A3kmlgHz0Q7',\n",
              "    'outputId': 'd2e6daaa-dbe2-4552-ef65-d5e8bbe0d9ea'},\n",
              "   'outputs': [{'name': 'stdout',\n",
              "     'output_type': 'stream',\n",
              "     'text': [\"{'APPLES': 0, 'BANANA': 1, 'ORANGE': 2, 'PINEAPPLE': 3, 'WATERMELON': 4}\\n\"]}],\n",
              "   'source': ['#checking the number of classes\\n',\n",
              "    'print(x_test.class_indices)']},\n",
              "  {'cell_type': 'code',\n",
              "   'execution_count': 21,\n",
              "   'metadata': {'colab': {'base_uri': 'https://localhost:8080/'},\n",
              "    'id': 'yGeKS68E0bSP',\n",
              "    'outputId': 'cd5bac4d-ffb6-464b-d6f0-841ef62e776d'},\n",
              "   'outputs': [{'data': {'text/plain': ['Counter({0: 995, 1: 1354, 2: 1019, 3: 275, 4: 475})']},\n",
              "     'execution_count': 21,\n",
              "     'metadata': {},\n",
              "     'output_type': 'execute_result'}],\n",
              "   'source': ['from collections import Counter as c\\n', 'c(x_train .labels)']},\n",
              "  {'cell_type': 'code',\n",
              "   'execution_count': 22,\n",
              "   'metadata': {'id': 'dx_5gTSAu0hY'},\n",
              "   'outputs': [],\n",
              "   'source': ['#Initializing the model\\n', 'model = Sequential()']},\n",
              "  {'cell_type': 'code',\n",
              "   'execution_count': 23,\n",
              "   'metadata': {'id': 'ufSbk5LVu9qU'},\n",
              "   'outputs': [],\n",
              "   'source': ['# add First convolution layer']},\n",
              "  {'cell_type': 'code',\n",
              "   'execution_count': 24,\n",
              "   'metadata': {'id': '62dYvr9WvHlF'},\n",
              "   'outputs': [],\n",
              "   'source': ['model.add(Convolution2D(32,(3,3),input_shape=(64,64,3),activation=\"relu\"))\\n',\n",
              "    '# 32 indicates => no of feature detectors\\n',\n",
              "    '#(3,3)=> kernel size (feature detector size)']},\n",
              "  {'cell_type': 'code',\n",
              "   'execution_count': 25,\n",
              "   'metadata': {'id': '0RoS09jlvROB'},\n",
              "   'outputs': [],\n",
              "   'source': ['# add Maxpooling layer']},\n",
              "  {'cell_type': 'code',\n",
              "   'execution_count': 26,\n",
              "   'metadata': {'id': '7tIjlFq_vaMc'},\n",
              "   'outputs': [],\n",
              "   'source': ['model.add(MaxPooling2D(pool_size=(2,2)))']},\n",
              "  {'cell_type': 'code',\n",
              "   'execution_count': 27,\n",
              "   'metadata': {'id': 'lnioOB-s9CaM'},\n",
              "   'outputs': [],\n",
              "   'source': ['#Second convolution layer and pooling\\n',\n",
              "    \"model.add(Convolution2D(32,(3,3),activation='relu'))\"]},\n",
              "  {'cell_type': 'code',\n",
              "   'execution_count': 28,\n",
              "   'metadata': {'id': 'bAcEug9x-Rqm'},\n",
              "   'outputs': [],\n",
              "   'source': ['model.add(MaxPooling2D(pool_size=(2,2)))']},\n",
              "  {'cell_type': 'code',\n",
              "   'execution_count': 29,\n",
              "   'metadata': {'id': 'hFOgQQQb_Inn'},\n",
              "   'outputs': [],\n",
              "   'source': ['#Flattening the layers\\n', 'model.add(Flatten())']},\n",
              "  {'cell_type': 'code',\n",
              "   'execution_count': 30,\n",
              "   'metadata': {'id': 'v1LSVWYs_g2v'},\n",
              "   'outputs': [],\n",
              "   'source': [\"model.add(Dense(units=128,activation='relu'))\"]},\n",
              "  {'cell_type': 'code',\n",
              "   'execution_count': 31,\n",
              "   'metadata': {'id': 'DKg4TBZZ_zT6'},\n",
              "   'outputs': [],\n",
              "   'source': [\"model.add(Dense(units=5,activation='softmax'))\"]},\n",
              "  {'cell_type': 'code',\n",
              "   'execution_count': 32,\n",
              "   'metadata': {'id': 'eCB4ZIxOvh4G'},\n",
              "   'outputs': [],\n",
              "   'source': ['# add flatten layer => input to your ANN']},\n",
              "  {'cell_type': 'code',\n",
              "   'execution_count': 33,\n",
              "   'metadata': {'id': 'agjb4SXivnq_'},\n",
              "   'outputs': [],\n",
              "   'source': ['model.add(Flatten())']},\n",
              "  {'cell_type': 'code',\n",
              "   'execution_count': 34,\n",
              "   'metadata': {},\n",
              "   'outputs': [],\n",
              "   'source': ['model.add(Dense(units=128,kernel_initializer=\"random_uniform\",activation=\"relu\"))']},\n",
              "  {'cell_type': 'code',\n",
              "   'execution_count': 35,\n",
              "   'metadata': {},\n",
              "   'outputs': [],\n",
              "   'source': ['model.add(Dense(units=5,kernel_initializer=\"random_uniform\",activation=\"softmax\"))\\n']},\n",
              "  {'cell_type': 'code',\n",
              "   'execution_count': 36,\n",
              "   'metadata': {},\n",
              "   'outputs': [],\n",
              "   'source': ['#compile the model\\n',\n",
              "    'model.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])']},\n",
              "  {'cell_type': 'code',\n",
              "   'execution_count': 44,\n",
              "   'metadata': {'id': '4fAss-XEyHCe'},\n",
              "   'outputs': [],\n",
              "   'source': ['#Train the model']},\n",
              "  {'cell_type': 'code',\n",
              "   'execution_count': 45,\n",
              "   'metadata': {},\n",
              "   'outputs': [{'name': 'stdout',\n",
              "     'output_type': 'stream',\n",
              "     'text': ['Epoch 1/10\\n']},\n",
              "    {'name': 'stderr',\n",
              "     'output_type': 'stream',\n",
              "     'text': ['/tmp/wsuser/ipykernel_164/4170907729.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\\n',\n",
              "      '  model.fit_generator(x_train,steps_per_epoch = 47 ,epochs = 10,validation_data = x_test,validation_steps = 10)\\n']},\n",
              "    {'name': 'stdout',\n",
              "     'output_type': 'stream',\n",
              "     'text': ['47/47 [==============================] - 10s 220ms/step - loss: 1.4920 - accuracy: 0.3271 - val_loss: 1.2936 - val_accuracy: 0.4062\\n',\n",
              "      'Epoch 2/10\\n',\n",
              "      '47/47 [==============================] - 10s 219ms/step - loss: 1.4914 - accuracy: 0.3205 - val_loss: 1.2874 - val_accuracy: 0.4656\\n',\n",
              "      'Epoch 3/10\\n',\n",
              "      '47/47 [==============================] - 10s 218ms/step - loss: 1.4792 - accuracy: 0.3307 - val_loss: 1.2546 - val_accuracy: 0.4781\\n',\n",
              "      'Epoch 4/10\\n',\n",
              "      '47/47 [==============================] - 11s 234ms/step - loss: 1.4971 - accuracy: 0.3273 - val_loss: 1.2869 - val_accuracy: 0.4531\\n',\n",
              "      'Epoch 5/10\\n',\n",
              "      '47/47 [==============================] - 10s 221ms/step - loss: 1.4939 - accuracy: 0.3178 - val_loss: 1.2880 - val_accuracy: 0.4719\\n',\n",
              "      'Epoch 6/10\\n',\n",
              "      '47/47 [==============================] - 10s 217ms/step - loss: 1.4852 - accuracy: 0.3178 - val_loss: 1.2793 - val_accuracy: 0.4375\\n',\n",
              "      'Epoch 7/10\\n',\n",
              "      '47/47 [==============================] - 10s 222ms/step - loss: 1.4894 - accuracy: 0.3260 - val_loss: 1.2865 - val_accuracy: 0.4156\\n',\n",
              "      'Epoch 8/10\\n',\n",
              "      '47/47 [==============================] - 10s 220ms/step - loss: 1.4987 - accuracy: 0.3211 - val_loss: 1.2744 - val_accuracy: 0.4750\\n',\n",
              "      'Epoch 9/10\\n',\n",
              "      '47/47 [==============================] - 11s 224ms/step - loss: 1.4952 - accuracy: 0.3220 - val_loss: 1.3020 - val_accuracy: 0.4156\\n',\n",
              "      'Epoch 10/10\\n',\n",
              "      '47/47 [==============================] - 11s 223ms/step - loss: 1.4679 - accuracy: 0.3391 - val_loss: 1.2756 - val_accuracy: 0.4156\\n']},\n",
              "    {'data': {'text/plain': ['<keras.callbacks.History at 0x7fec605ddee0>']},\n",
              "     'execution_count': 45,\n",
              "     'metadata': {},\n",
              "     'output_type': 'execute_result'}],\n",
              "   'source': ['model.fit_generator(x_train,steps_per_epoch = 47 ,epochs = 10,validation_data = x_test,validation_steps = 10)\\n',\n",
              "    '#steps_per_epoch = no of train images/batch size\\n',\n",
              "    '#validation_steps = no of test images/batch size']},\n",
              "  {'cell_type': 'code',\n",
              "   'execution_count': 46,\n",
              "   'metadata': {'id': '5nrwRs8k5rSf'},\n",
              "   'outputs': [],\n",
              "   'source': ['model.save(\"nutrition.h5\")']},\n",
              "  {'cell_type': 'code',\n",
              "   'execution_count': 47,\n",
              "   'metadata': {},\n",
              "   'outputs': [{'name': 'stdout',\n",
              "     'output_type': 'stream',\n",
              "     'text': ['nutrition.h5\\r\\n']}],\n",
              "   'source': ['!tar -zcvf image-classification-model_new.tgz nutrition.h5']},\n",
              "  {'cell_type': 'code',\n",
              "   'execution_count': 48,\n",
              "   'metadata': {},\n",
              "   'outputs': [{'name': 'stdout',\n",
              "     'output_type': 'stream',\n",
              "     'text': ['\\x1b[0m\\x1b[01;34mDataset\\x1b[0m/\\r\\n',\n",
              "      'image-classification-model_new.tgz\\r\\n',\n",
              "      'nutrition.h5\\r\\n']}],\n",
              "   'source': ['ls -1']},\n",
              "  {'cell_type': 'code',\n",
              "   'execution_count': 49,\n",
              "   'metadata': {},\n",
              "   'outputs': [{'name': 'stdout',\n",
              "     'output_type': 'stream',\n",
              "     'text': ['Collecting watson-machine-learning-client\\n',\n",
              "      '  Downloading watson_machine_learning_client-1.0.391-py3-none-any.whl (538 kB)\\n',\n",
              "      '\\x1b[K     |████████████████████████████████| 538 kB 20.1 MB/s eta 0:00:01\\n',\n",
              "      '\\x1b[?25hRequirement already satisfied: ibm-cos-sdk in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (2.11.0)\\n',\n",
              "      'Requirement already satisfied: certifi in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (2022.9.24)\\n',\n",
              "      'Requirement already satisfied: tabulate in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (0.8.9)\\n',\n",
              "      'Requirement already satisfied: requests in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (2.26.0)\\n',\n",
              "      'Requirement already satisfied: lomond in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (0.3.3)\\n',\n",
              "      'Requirement already satisfied: tqdm in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (4.62.3)\\n',\n",
              "      'Requirement already satisfied: boto3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (1.18.21)\\n',\n",
              "      'Requirement already satisfied: urllib3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (1.26.7)\\n',\n",
              "      'Requirement already satisfied: pandas in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (1.3.4)\\n',\n",
              "      'Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from boto3->watson-machine-learning-client) (0.5.0)\\n',\n",
              "      'Requirement already satisfied: botocore<1.22.0,>=1.21.21 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from boto3->watson-machine-learning-client) (1.21.41)\\n',\n",
              "      'Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from boto3->watson-machine-learning-client) (0.10.0)\\n',\n",
              "      'Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from botocore<1.22.0,>=1.21.21->boto3->watson-machine-learning-client) (2.8.2)\\n',\n",
              "      'Requirement already satisfied: six>=1.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.22.0,>=1.21.21->boto3->watson-machine-learning-client) (1.15.0)\\n',\n",
              "      'Requirement already satisfied: ibm-cos-sdk-s3transfer==2.11.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm-cos-sdk->watson-machine-learning-client) (2.11.0)\\n',\n",
              "      'Requirement already satisfied: ibm-cos-sdk-core==2.11.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm-cos-sdk->watson-machine-learning-client) (2.11.0)\\n',\n",
              "      'Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests->watson-machine-learning-client) (3.3)\\n',\n",
              "      'Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests->watson-machine-learning-client) (2.0.4)\\n',\n",
              "      'Requirement already satisfied: pytz>=2017.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from pandas->watson-machine-learning-client) (2021.3)\\n',\n",
              "      'Requirement already satisfied: numpy>=1.17.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from pandas->watson-machine-learning-client) (1.20.3)\\n',\n",
              "      'Installing collected packages: watson-machine-learning-client\\n',\n",
              "      'Successfully installed watson-machine-learning-client-1.0.391\\n']}],\n",
              "   'source': ['!pip install watson-machine-learning-client']},\n",
              "  {'cell_type': 'code',\n",
              "   'execution_count': 50,\n",
              "   'metadata': {},\n",
              "   'outputs': [],\n",
              "   'source': ['from ibm_watson_machine_learning import APIClient\\n',\n",
              "    'wml_credentials={\\n',\n",
              "    '    \"url\":\"https://us-south.ml.cloud.ibm.com\",\\n',\n",
              "    '    \"apikey\":\"BPFGcOrCf3sroRy3uKOPGozsmIL-5oVDv4A_lru2IpMS\"\\n',\n",
              "    '    \\n',\n",
              "    '}\\n',\n",
              "    '\\n',\n",
              "    'client=APIClient(wml_credentials)']},\n",
              "  {'cell_type': 'code',\n",
              "   'execution_count': 51,\n",
              "   'metadata': {},\n",
              "   'outputs': [{'data': {'text/plain': ['<ibm_watson_machine_learning.client.APIClient at 0x7fec60578040>']},\n",
              "     'execution_count': 51,\n",
              "     'metadata': {},\n",
              "     'output_type': 'execute_result'}],\n",
              "   'source': ['client']},\n",
              "  {'cell_type': 'code',\n",
              "   'execution_count': 52,\n",
              "   'metadata': {},\n",
              "   'outputs': [],\n",
              "   'source': [' def guid_from_space_name(client, space_name):\\n',\n",
              "    '     space=client.spaces.get_details()\\n',\n",
              "    '     #print(space)\\n',\n",
              "    \"     return(next(item for item in space['resources'] if item['entity']['name']== space_name)['metadata']['id'])\"]},\n",
              "  {'cell_type': 'code',\n",
              "   'execution_count': 53,\n",
              "   'metadata': {},\n",
              "   'outputs': [{'name': 'stdout',\n",
              "     'output_type': 'stream',\n",
              "     'text': ['Space UID =ba02adea-7e10-4237-81e7-eaf084fe4102\\n']}],\n",
              "   'source': [\"space_uid=guid_from_space_name(client,'imageclassification') #imageclassification is the deployment space name\\n\",\n",
              "    'print(\"Space UID =\"+space_uid)']},\n",
              "  {'cell_type': 'code',\n",
              "   'execution_count': 54,\n",
              "   'metadata': {},\n",
              "   'outputs': [{'data': {'text/plain': [\"'SUCCESS'\"]},\n",
              "     'execution_count': 54,\n",
              "     'metadata': {},\n",
              "     'output_type': 'execute_result'}],\n",
              "   'source': ['client.set.default_space(space_uid)']},\n",
              "  {'cell_type': 'code',\n",
              "   'execution_count': 55,\n",
              "   'metadata': {},\n",
              "   'outputs': [{'name': 'stdout',\n",
              "     'output_type': 'stream',\n",
              "     'text': ['-----------------------------  ------------------------------------  ----\\n',\n",
              "      'NAME                           ASSET_ID                              TYPE\\n',\n",
              "      'default_py3.6                  0062b8c9-8b7d-44a0-a9b9-46c416adcbd9  base\\n',\n",
              "      'kernel-spark3.2-scala2.12      020d69ce-7ac1-5e68-ac1a-31189867356a  base\\n',\n",
              "      'pytorch-onnx_1.3-py3.7-edt     069ea134-3346-5748-b513-49120e15d288  base\\n',\n",
              "      'scikit-learn_0.20-py3.6        09c5a1d0-9c1e-4473-a344-eb7b665ff687  base\\n',\n",
              "      'spark-mllib_3.0-scala_2.12     09f4cff0-90a7-5899-b9ed-1ef348aebdee  base\\n',\n",
              "      'pytorch-onnx_rt22.1-py3.9      0b848dd4-e681-5599-be41-b5f6fccc6471  base\\n',\n",
              "      'ai-function_0.1-py3.6          0cdb0f1e-5376-4f4d-92dd-da3b69aa9bda  base\\n',\n",
              "      'shiny-r3.6                     0e6e79df-875e-4f24-8ae9-62dcc2148306  base\\n',\n",
              "      'tensorflow_2.4-py3.7-horovod   1092590a-307d-563d-9b62-4eb7d64b3f22  base\\n',\n",
              "      'pytorch_1.1-py3.6              10ac12d6-6b30-4ccd-8392-3e922c096a92  base\\n',\n",
              "      'tensorflow_1.15-py3.6-ddl      111e41b3-de2d-5422-a4d6-bf776828c4b7  base\\n',\n",
              "      'runtime-22.1-py3.9             12b83a17-24d8-5082-900f-0ab31fbfd3cb  base\\n',\n",
              "      'scikit-learn_0.22-py3.6        154010fa-5b3b-4ac1-82af-4d5ee5abbc85  base\\n',\n",
              "      'default_r3.6                   1b70aec3-ab34-4b87-8aa0-a4a3c8296a36  base\\n',\n",
              "      'pytorch-onnx_1.3-py3.6         1bc6029a-cc97-56da-b8e0-39c3880dbbe7  base\\n',\n",
              "      'kernel-spark3.3-r3.6           1c9e5454-f216-59dd-a20e-474a5cdf5988  base\\n',\n",
              "      'pytorch-onnx_rt22.1-py3.9-edt  1d362186-7ad5-5b59-8b6c-9d0880bde37f  base\\n',\n",
              "      'tensorflow_2.1-py3.6           1eb25b84-d6ed-5dde-b6a5-3fbdf1665666  base\\n',\n",
              "      'spark-mllib_3.2                20047f72-0a98-58c7-9ff5-a77b012eb8f5  base\\n',\n",
              "      'tensorflow_2.4-py3.8-horovod   217c16f6-178f-56bf-824a-b19f20564c49  base\\n',\n",
              "      'runtime-22.1-py3.9-cuda        26215f05-08c3-5a41-a1b0-da66306ce658  base\\n',\n",
              "      'do_py3.8                       295addb5-9ef9-547e-9bf4-92ae3563e720  base\\n',\n",
              "      'autoai-ts_3.8-py3.8            2aa0c932-798f-5ae9-abd6-15e0c2402fb5  base\\n',\n",
              "      'tensorflow_1.15-py3.6          2b73a275-7cbf-420b-a912-eae7f436e0bc  base\\n',\n",
              "      'kernel-spark3.3-py3.9          2b7961e2-e3b1-5a8c-a491-482c8368839a  base\\n',\n",
              "      'pytorch_1.2-py3.6              2c8ef57d-2687-4b7d-acce-01f94976dac1  base\\n',\n",
              "      'spark-mllib_2.3                2e51f700-bca0-4b0d-88dc-5c6791338875  base\\n',\n",
              "      'pytorch-onnx_1.1-py3.6-edt     32983cea-3f32-4400-8965-dde874a8d67e  base\\n',\n",
              "      'spark-mllib_3.0-py37           36507ebe-8770-55ba-ab2a-eafe787600e9  base\\n',\n",
              "      'spark-mllib_2.4                390d21f8-e58b-4fac-9c55-d7ceda621326  base\\n',\n",
              "      'xgboost_0.82-py3.6             39e31acd-5f30-41dc-ae44-60233c80306e  base\\n',\n",
              "      'pytorch-onnx_1.2-py3.6-edt     40589d0e-7019-4e28-8daa-fb03b6f4fe12  base\\n',\n",
              "      'default_r36py38                41c247d3-45f8-5a71-b065-8580229facf0  base\\n',\n",
              "      'autoai-ts_rt22.1-py3.9         4269d26e-07ba-5d40-8f66-2d495b0c71f7  base\\n',\n",
              "      'autoai-obm_3.0                 42b92e18-d9ab-567f-988a-4240ba1ed5f7  base\\n',\n",
              "      'pmml-3.0_4.3                   493bcb95-16f1-5bc5-bee8-81b8af80e9c7  base\\n',\n",
              "      'spark-mllib_2.4-r_3.6          49403dff-92e9-4c87-a3d7-a42d0021c095  base\\n',\n",
              "      'xgboost_0.90-py3.6             4ff8d6c2-1343-4c18-85e1-689c965304d3  base\\n',\n",
              "      'pytorch-onnx_1.1-py3.6         50f95b2a-bc16-43bb-bc94-b0bed208c60b  base\\n',\n",
              "      'autoai-ts_3.9-py3.8            52c57136-80fa-572e-8728-a5e7cbb42cde  base\\n',\n",
              "      'spark-mllib_2.4-scala_2.11     55a70f99-7320-4be5-9fb9-9edb5a443af5  base\\n',\n",
              "      'spark-mllib_3.0                5c1b0ca2-4977-5c2e-9439-ffd44ea8ffe9  base\\n',\n",
              "      'autoai-obm_2.0                 5c2e37fa-80b8-5e77-840f-d912469614ee  base\\n',\n",
              "      'spss-modeler_18.1              5c3cad7e-507f-4b2a-a9a3-ab53a21dee8b  base\\n',\n",
              "      'cuda-py3.8                     5d3232bf-c86b-5df4-a2cd-7bb870a1cd4e  base\\n',\n",
              "      'autoai-kb_3.1-py3.7            632d4b22-10aa-5180-88f0-f52dfb6444d7  base\\n',\n",
              "      'pytorch-onnx_1.7-py3.8         634d3cdc-b562-5bf9-a2d4-ea90a478456b  base\\n',\n",
              "      'spark-mllib_2.3-r_3.6          6586b9e3-ccd6-4f92-900f-0f8cb2bd6f0c  base\\n',\n",
              "      'tensorflow_2.4-py3.7           65e171d7-72d1-55d9-8ebb-f813d620c9bb  base\\n',\n",
              "      'spss-modeler_18.2              687eddc9-028a-4117-b9dd-e57b36f1efa5  base\\n',\n",
              "      '-----------------------------  ------------------------------------  ----\\n',\n",
              "      \"Note: Only first 50 records were displayed. To display more use 'limit' parameter.\\n\"]}],\n",
              "   'source': ['client.software_specifications.list()']},\n",
              "  {'cell_type': 'code',\n",
              "   'execution_count': 56,\n",
              "   'metadata': {},\n",
              "   'outputs': [],\n",
              "   'source': [\"software_space_uid=client.software_specifications.get_uid_by_name('tensorflow_rt22.1-py3.9')\"]},\n",
              "  {'cell_type': 'code',\n",
              "   'execution_count': 57,\n",
              "   'metadata': {},\n",
              "   'outputs': [{'data': {'text/plain': [\"'acd9c798-6974-5d2f-a657-ce06e986df4d'\"]},\n",
              "     'execution_count': 57,\n",
              "     'metadata': {},\n",
              "     'output_type': 'execute_result'}],\n",
              "   'source': ['software_space_uid']},\n",
              "  {'cell_type': 'code',\n",
              "   'execution_count': 58,\n",
              "   'metadata': {},\n",
              "   'outputs': [],\n",
              "   'source': [\"model_details=client.repository.store_model(model='image-classification-model_new.tgz',meta_props={\\n\",\n",
              "    '    client.repository.ModelMetaNames.NAME:\"CNN\",\\n',\n",
              "    \"    client.repository.ModelMetaNames.TYPE:'tensorflow_2.7',\\n\",\n",
              "    '    client.repository.ModelMetaNames.SOFTWARE_SPEC_UID:software_space_uid}\\n',\n",
              "    '                                             )\\n',\n",
              "    'model_id = client.repository.get_model_id(model_details)']},\n",
              "  {'cell_type': 'code',\n",
              "   'execution_count': 59,\n",
              "   'metadata': {},\n",
              "   'outputs': [{'data': {'text/plain': [\"'f3e12114-24f4-4bae-9d60-2897d27e7ce6'\"]},\n",
              "     'execution_count': 59,\n",
              "     'metadata': {},\n",
              "     'output_type': 'execute_result'}],\n",
              "   'source': ['model_id']},\n",
              "  {'cell_type': 'code',\n",
              "   'execution_count': 60,\n",
              "   'metadata': {},\n",
              "   'outputs': [{'name': 'stdout',\n",
              "     'output_type': 'stream',\n",
              "     'text': [\"Successfully saved model content to file: 'my_model.tar.gz'\\n\"]},\n",
              "    {'data': {'text/plain': [\"'/home/wsuser/work/my_model.tar.gz'\"]},\n",
              "     'execution_count': 60,\n",
              "     'metadata': {},\n",
              "     'output_type': 'execute_result'}],\n",
              "   'source': [\"client.repository.download(model_id, 'my_model.tar.gz')\"]}],\n",
              " 'metadata': {'colab': {'provenance': []},\n",
              "  'kernelspec': {'display_name': 'Python 3.9',\n",
              "   'language': 'python',\n",
              "   'name': 'python3'},\n",
              "  'language_info': {'codemirror_mode': {'name': 'ipython', 'version': 3},\n",
              "   'file_extension': '.py',\n",
              "   'mimetype': 'text/x-python',\n",
              "   'name': 'python',\n",
              "   'nbconvert_exporter': 'python',\n",
              "   'pygments_lexer': 'ipython3',\n",
              "   'version': '3.9.13'}},\n",
              " 'nbformat': 4,\n",
              " 'nbformat_minor': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "{\n",
        " \"cells\": [\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 3,\n",
        "   \"metadata\": {\n",
        "    \"id\": \"-4U2x7XApAPv\"\n",
        "   },\n",
        "   \"outputs\": [\n",
        "    {\n",
        "     \"data\": {\n",
        "      \"text/plain\": [\n",
        "       \"'/home/wsuser/work'\"\n",
        "      ]\n",
        "     },\n",
        "     \"execution_count\": 3,\n",
        "     \"metadata\": {},\n",
        "     \"output_type\": \"execute_result\"\n",
        "    }\n",
        "   ],\n",
        "   \"source\": [\n",
        "    \"pwd\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 7,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [\n",
        "    {\n",
        "     \"name\": \"stdout\",\n",
        "     \"output_type\": \"stream\",\n",
        "     \"text\": [\n",
        "      \"Collecting keras==2.7.0\\n\",\n",
        "      \"  Downloading keras-2.7.0-py2.py3-none-any.whl (1.3 MB)\\n\",\n",
        "      \"\\u001b[K     |████████████████████████████████| 1.3 MB 22.6 MB/s eta 0:00:01\\n\",\n",
        "      \"\\u001b[?25hInstalling collected packages: keras\\n\",\n",
        "      \"  Attempting uninstall: keras\\n\",\n",
        "      \"    Found existing installation: keras 2.10.0\\n\",\n",
        "      \"    Uninstalling keras-2.10.0:\\n\",\n",
        "      \"      Successfully uninstalled keras-2.10.0\\n\",\n",
        "      \"\\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\\n\",\n",
        "      \"tensorflow 2.10.0 requires keras<2.11,>=2.10.0, but you have keras 2.7.0 which is incompatible.\\n\",\n",
        "      \"tensorflow-text 2.7.3 requires tensorflow<2.8,>=2.7.0, but you have tensorflow 2.10.0 which is incompatible.\\n\",\n",
        "      \"autoai-ts-libs 1.1.9 requires tensorflow<2.8,>=2.7.0; python_version >= \\\"3.9\\\", but you have tensorflow 2.10.0 which is incompatible.\\u001b[0m\\n\",\n",
        "      \"Successfully installed keras-2.7.0\\n\",\n",
        "      \"Requirement already satisfied: tensorflow==2.10.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (2.10.0)\\n\",\n",
        "      \"Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.10.0) (1.42.0)\\n\",\n",
        "      \"Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.10.0) (3.3.0)\\n\",\n",
        "      \"Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.10.0) (1.3.0)\\n\",\n",
        "      \"Requirement already satisfied: numpy>=1.20 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.10.0) (1.20.3)\\n\",\n",
        "      \"Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.10.0) (1.6.3)\\n\",\n",
        "      \"Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.10.0) (0.4.0)\\n\",\n",
        "      \"Requirement already satisfied: setuptools in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.10.0) (58.0.4)\\n\",\n",
        "      \"Requirement already satisfied: tensorboard<2.11,>=2.10 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.10.0) (2.10.1)\\n\",\n",
        "      \"Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.10.0) (0.2.0)\\n\",\n",
        "      \"Requirement already satisfied: keras-preprocessing>=1.1.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.10.0) (1.1.2)\\n\",\n",
        "      \"Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.10.0) (4.1.1)\\n\",\n",
        "      \"Requirement already satisfied: flatbuffers>=2.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.10.0) (2.0)\\n\",\n",
        "      \"Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.10.0) (1.1.0)\\n\",\n",
        "      \"Requirement already satisfied: h5py>=2.9.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.10.0) (3.2.1)\\n\",\n",
        "      \"Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.10.0) (0.23.1)\\n\",\n",
        "      \"Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.10.0) (2.10.0)\\n\",\n",
        "      \"Requirement already satisfied: protobuf<3.20,>=3.9.2 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.10.0) (3.19.1)\\n\",\n",
        "      \"Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.10.0) (1.12.1)\\n\",\n",
        "      \"Collecting keras<2.11,>=2.10.0\\n\",\n",
        "      \"  Using cached keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\\n\",\n",
        "      \"Requirement already satisfied: six>=1.12.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.10.0) (1.15.0)\\n\",\n",
        "      \"Requirement already satisfied: libclang>=13.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.10.0) (14.0.6)\\n\",\n",
        "      \"Requirement already satisfied: packaging in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.10.0) (21.3)\\n\",\n",
        "      \"Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow==2.10.0) (0.37.0)\\n\",\n",
        "      \"Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.4.4)\\n\",\n",
        "      \"Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (1.6.0)\\n\",\n",
        "      \"Requirement already satisfied: markdown>=2.6.8 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.3.3)\\n\",\n",
        "      \"Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.6.1)\\n\",\n",
        "      \"Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.0.2)\\n\",\n",
        "      \"Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (1.23.0)\\n\",\n",
        "      \"Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.26.0)\\n\",\n",
        "      \"Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (4.7.2)\\n\",\n",
        "      \"Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (4.2.2)\\n\",\n",
        "      \"Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.2.8)\\n\",\n",
        "      \"Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (1.3.0)\\n\",\n",
        "      \"Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.4.8)\\n\",\n",
        "      \"Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (1.26.7)\\n\",\n",
        "      \"Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.0.4)\\n\",\n",
        "      \"Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.3)\\n\",\n",
        "      \"Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2022.9.24)\\n\",\n",
        "      \"Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.2.1)\\n\",\n",
        "      \"Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from packaging->tensorflow==2.10.0) (3.0.4)\\n\",\n",
        "      \"Installing collected packages: keras\\n\",\n",
        "      \"  Attempting uninstall: keras\\n\",\n",
        "      \"    Found existing installation: keras 2.7.0\\n\",\n",
        "      \"    Uninstalling keras-2.7.0:\\n\",\n",
        "      \"      Successfully uninstalled keras-2.7.0\\n\",\n",
        "      \"\\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\\n\",\n",
        "      \"tensorflow-text 2.7.3 requires tensorflow<2.8,>=2.7.0, but you have tensorflow 2.10.0 which is incompatible.\\n\",\n",
        "      \"autoai-ts-libs 1.1.9 requires tensorflow<2.8,>=2.7.0; python_version >= \\\"3.9\\\", but you have tensorflow 2.10.0 which is incompatible.\\u001b[0m\\n\",\n",
        "      \"Successfully installed keras-2.10.0\\n\"\n",
        "     ]\n",
        "    }\n",
        "   ],\n",
        "   \"source\": [\n",
        "    \"!pip install keras==2.7.0\\n\",\n",
        "    \"!pip install tensorflow==2.10.0\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 8,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"#import keras libraries\\n\",\n",
        "    \"from keras.models import Sequential #api,se\\n\",\n",
        "    \"from keras.layers import Dense #add layers\\n\",\n",
        "    \"from keras.layers import Convolution2D #con\\n\",\n",
        "    \"from keras.layers import MaxPooling2D\\n\",\n",
        "    \"from keras.layers import Flatten\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 9,\n",
        "   \"metadata\": {\n",
        "    \"id\": \"GUqs8zuap0Ro\"\n",
        "   },\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"#image preprocessing(or) image augmentation\\n\",\n",
        "    \"from keras.preprocessing.image import ImageDataGenerator\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 10,\n",
        "   \"metadata\": {\n",
        "    \"id\": \"t44vJdxpqO67\"\n",
        "   },\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"train_datagen = ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True,vertical_flip=True)\\n\",\n",
        "    \"#rescale => rescaling pixel value from 0 to 255 to 0 to 1\\n\",\n",
        "    \"#shear_range=> counter clock wise rotation(anti clock)\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 11,\n",
        "   \"metadata\": {\n",
        "    \"id\": \"bPtjB_31qZLl\"\n",
        "   },\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"test_datagen = ImageDataGenerator(rescale=1./255)\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 12,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"\\n\",\n",
        "    \"import os, types\\n\",\n",
        "    \"import pandas as pd\\n\",\n",
        "    \"from botocore.client import Config\\n\",\n",
        "    \"import ibm_boto3\\n\",\n",
        "    \"\\n\",\n",
        "    \"def __iter__(self): return 0\\n\",\n",
        "    \"\\n\",\n",
        "    \"# @hidden_cell\\n\",\n",
        "    \"# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\\n\",\n",
        "    \"# You might want to remove those credentials before you share the notebook.\\n\",\n",
        "    \"cos_client = ibm_boto3.client(service_name='s3',\\n\",\n",
        "    \"    ibm_api_key_id='6L2of0JKTob3sCgpaW9F6IcVfD7HJNHrn9Owefk-q5wo',\\n\",\n",
        "    \"    ibm_auth_endpoint=\\\"https://iam.cloud.ibm.com/oidc/token\\\",\\n\",\n",
        "    \"    config=Config(signature_version='oauth'),\\n\",\n",
        "    \"    endpoint_url='https://s3.private.us.cloud-object-storage.appdomain.cloud')\\n\",\n",
        "    \"\\n\",\n",
        "    \"bucket = 'imageclassification-donotdelete-pr-fleoxflx4ga1rw'\\n\",\n",
        "    \"object_key = 'Dataset-20221107T052301Z-001.zip'\\n\",\n",
        "    \"\\n\",\n",
        "    \"streaming_body_1 = cos_client.get_object(Bucket=bucket, Key=object_key)['Body']\\n\",\n",
        "    \"\\n\",\n",
        "    \"# Your data file was loaded into a botocore.response.StreamingBody object.\\n\",\n",
        "    \"# Please read the documentation of ibm_boto3 and pandas to learn more about the possibilities to load the data.\\n\",\n",
        "    \"# ibm_boto3 documentation: https://ibm.github.io/ibm-cos-sdk-python/\\n\",\n",
        "    \"# pandas documentation: http://pandas.pydata.org/\\n\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 13,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"from io import BytesIO\\n\",\n",
        "    \"import zipfile\\n\",\n",
        "    \"unzip=zipfile.ZipFile(BytesIO(streaming_body_1.read()),'r')\\n\",\n",
        "    \"file_paths=unzip.namelist()\\n\",\n",
        "    \"for path in file_paths:\\n\",\n",
        "    \"    unzip.extract(path)\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 14,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [\n",
        "    {\n",
        "     \"name\": \"stdout\",\n",
        "     \"output_type\": \"stream\",\n",
        "     \"text\": [\n",
        "      \"\\u001b[0m\\u001b[01;34mDataset\\u001b[0m/\\r\\n\"\n",
        "     ]\n",
        "    }\n",
        "   ],\n",
        "   \"source\": [\n",
        "    \"ls\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 15,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [\n",
        "    {\n",
        "     \"data\": {\n",
        "      \"text/plain\": [\n",
        "       \"'/home/wsuser/work'\"\n",
        "      ]\n",
        "     },\n",
        "     \"execution_count\": 15,\n",
        "     \"metadata\": {},\n",
        "     \"output_type\": \"execute_result\"\n",
        "    }\n",
        "   ],\n",
        "   \"source\": [\n",
        "    \"pwd\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 16,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"import os \\n\",\n",
        "    \"filenames = os.listdir('/home/wsuser/work/Dataset')\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 17,\n",
        "   \"metadata\": {\n",
        "    \"colab\": {\n",
        "     \"base_uri\": \"https://localhost:8080/\"\n",
        "    },\n",
        "    \"id\": \"ltTuui5Kqdtp\",\n",
        "    \"outputId\": \"2f168c3f-c51e-4c92-dc28-3d4ea011d4da\"\n",
        "   },\n",
        "   \"outputs\": [\n",
        "    {\n",
        "     \"name\": \"stdout\",\n",
        "     \"output_type\": \"stream\",\n",
        "     \"text\": [\n",
        "      \"Found 4118 images belonging to 5 classes.\\n\"\n",
        "     ]\n",
        "    }\n",
        "   ],\n",
        "   \"source\": [\n",
        "    \"x_train = train_datagen.flow_from_directory(\\\"/home/wsuser/work/Dataset/TRAIN_SET\\\",target_size=(64,64),batch_size=32,class_mode=\\\"categorical\\\")\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 18,\n",
        "   \"metadata\": {\n",
        "    \"colab\": {\n",
        "     \"base_uri\": \"https://localhost:8080/\"\n",
        "    },\n",
        "    \"id\": \"U9WzDTJHuiAh\",\n",
        "    \"outputId\": \"87f6e98f-1cba-473a-b803-faa60d4eeb7d\"\n",
        "   },\n",
        "   \"outputs\": [\n",
        "    {\n",
        "     \"name\": \"stdout\",\n",
        "     \"output_type\": \"stream\",\n",
        "     \"text\": [\n",
        "      \"Found 929 images belonging to 5 classes.\\n\"\n",
        "     ]\n",
        "    }\n",
        "   ],\n",
        "   \"source\": [\n",
        "    \"x_test = test_datagen.flow_from_directory(\\\"/home/wsuser/work/Dataset/TEST_SET\\\",target_size=(64,64),batch_size=32,class_mode=\\\"categorical\\\")\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 19,\n",
        "   \"metadata\": {\n",
        "    \"colab\": {\n",
        "     \"base_uri\": \"https://localhost:8080/\"\n",
        "    },\n",
        "    \"id\": \"bApCdADGup8T\",\n",
        "    \"outputId\": \"d57ab51e-f9c3-47b2-f19c-f25f10a7aec7\"\n",
        "   },\n",
        "   \"outputs\": [\n",
        "    {\n",
        "     \"data\": {\n",
        "      \"text/plain\": [\n",
        "       \"{'APPLES': 0, 'BANANA': 1, 'ORANGE': 2, 'PINEAPPLE': 3, 'WATERMELON': 4}\"\n",
        "      ]\n",
        "     },\n",
        "     \"execution_count\": 19,\n",
        "     \"metadata\": {},\n",
        "     \"output_type\": \"execute_result\"\n",
        "    }\n",
        "   ],\n",
        "   \"source\": [\n",
        "    \"x_train.class_indices\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 20,\n",
        "   \"metadata\": {\n",
        "    \"colab\": {\n",
        "     \"base_uri\": \"https://localhost:8080/\"\n",
        "    },\n",
        "    \"id\": \"9A3kmlgHz0Q7\",\n",
        "    \"outputId\": \"d2e6daaa-dbe2-4552-ef65-d5e8bbe0d9ea\"\n",
        "   },\n",
        "   \"outputs\": [\n",
        "    {\n",
        "     \"name\": \"stdout\",\n",
        "     \"output_type\": \"stream\",\n",
        "     \"text\": [\n",
        "      \"{'APPLES': 0, 'BANANA': 1, 'ORANGE': 2, 'PINEAPPLE': 3, 'WATERMELON': 4}\\n\"\n",
        "     ]\n",
        "    }\n",
        "   ],\n",
        "   \"source\": [\n",
        "    \"#checking the number of classes\\n\",\n",
        "    \"print(x_test.class_indices)\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 21,\n",
        "   \"metadata\": {\n",
        "    \"colab\": {\n",
        "     \"base_uri\": \"https://localhost:8080/\"\n",
        "    },\n",
        "    \"id\": \"yGeKS68E0bSP\",\n",
        "    \"outputId\": \"cd5bac4d-ffb6-464b-d6f0-841ef62e776d\"\n",
        "   },\n",
        "   \"outputs\": [\n",
        "    {\n",
        "     \"data\": {\n",
        "      \"text/plain\": [\n",
        "       \"Counter({0: 995, 1: 1354, 2: 1019, 3: 275, 4: 475})\"\n",
        "      ]\n",
        "     },\n",
        "     \"execution_count\": 21,\n",
        "     \"metadata\": {},\n",
        "     \"output_type\": \"execute_result\"\n",
        "    }\n",
        "   ],\n",
        "   \"source\": [\n",
        "    \"from collections import Counter as c\\n\",\n",
        "    \"c(x_train .labels)\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 22,\n",
        "   \"metadata\": {\n",
        "    \"id\": \"dx_5gTSAu0hY\"\n",
        "   },\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"#Initializing the model\\n\",\n",
        "    \"model = Sequential()\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 23,\n",
        "   \"metadata\": {\n",
        "    \"id\": \"ufSbk5LVu9qU\"\n",
        "   },\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"# add First convolution layer\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 24,\n",
        "   \"metadata\": {\n",
        "    \"id\": \"62dYvr9WvHlF\"\n",
        "   },\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"model.add(Convolution2D(32,(3,3),input_shape=(64,64,3),activation=\\\"relu\\\"))\\n\",\n",
        "    \"# 32 indicates => no of feature detectors\\n\",\n",
        "    \"#(3,3)=> kernel size (feature detector size)\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 25,\n",
        "   \"metadata\": {\n",
        "    \"id\": \"0RoS09jlvROB\"\n",
        "   },\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"# add Maxpooling layer\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 26,\n",
        "   \"metadata\": {\n",
        "    \"id\": \"7tIjlFq_vaMc\"\n",
        "   },\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"model.add(MaxPooling2D(pool_size=(2,2)))\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 27,\n",
        "   \"metadata\": {\n",
        "    \"id\": \"lnioOB-s9CaM\"\n",
        "   },\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"#Second convolution layer and pooling\\n\",\n",
        "    \"model.add(Convolution2D(32,(3,3),activation='relu'))\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 28,\n",
        "   \"metadata\": {\n",
        "    \"id\": \"bAcEug9x-Rqm\"\n",
        "   },\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"model.add(MaxPooling2D(pool_size=(2,2)))\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 29,\n",
        "   \"metadata\": {\n",
        "    \"id\": \"hFOgQQQb_Inn\"\n",
        "   },\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"#Flattening the layers\\n\",\n",
        "    \"model.add(Flatten())\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 30,\n",
        "   \"metadata\": {\n",
        "    \"id\": \"v1LSVWYs_g2v\"\n",
        "   },\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"model.add(Dense(units=128,activation='relu'))\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 31,\n",
        "   \"metadata\": {\n",
        "    \"id\": \"DKg4TBZZ_zT6\"\n",
        "   },\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"model.add(Dense(units=5,activation='softmax'))\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 32,\n",
        "   \"metadata\": {\n",
        "    \"id\": \"eCB4ZIxOvh4G\"\n",
        "   },\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"# add flatten layer => input to your ANN\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 33,\n",
        "   \"metadata\": {\n",
        "    \"id\": \"agjb4SXivnq_\"\n",
        "   },\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"model.add(Flatten())\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 34,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"model.add(Dense(units=128,kernel_initializer=\\\"random_uniform\\\",activation=\\\"relu\\\"))\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 35,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"model.add(Dense(units=5,kernel_initializer=\\\"random_uniform\\\",activation=\\\"softmax\\\"))\\n\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 36,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"#compile the model\\n\",\n",
        "    \"model.compile(loss=\\\"categorical_crossentropy\\\",optimizer=\\\"adam\\\",metrics=[\\\"accuracy\\\"])\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 44,\n",
        "   \"metadata\": {\n",
        "    \"id\": \"4fAss-XEyHCe\"\n",
        "   },\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"#Train the model\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 45,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [\n",
        "    {\n",
        "     \"name\": \"stdout\",\n",
        "     \"output_type\": \"stream\",\n",
        "     \"text\": [\n",
        "      \"Epoch 1/10\\n\"\n",
        "     ]\n",
        "    },\n",
        "    {\n",
        "     \"name\": \"stderr\",\n",
        "     \"output_type\": \"stream\",\n",
        "     \"text\": [\n",
        "      \"/tmp/wsuser/ipykernel_164/4170907729.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\\n\",\n",
        "      \"  model.fit_generator(x_train,steps_per_epoch = 47 ,epochs = 10,validation_data = x_test,validation_steps = 10)\\n\"\n",
        "     ]\n",
        "    },\n",
        "    {\n",
        "     \"name\": \"stdout\",\n",
        "     \"output_type\": \"stream\",\n",
        "     \"text\": [\n",
        "      \"47/47 [==============================] - 10s 220ms/step - loss: 1.4920 - accuracy: 0.3271 - val_loss: 1.2936 - val_accuracy: 0.4062\\n\",\n",
        "      \"Epoch 2/10\\n\",\n",
        "      \"47/47 [==============================] - 10s 219ms/step - loss: 1.4914 - accuracy: 0.3205 - val_loss: 1.2874 - val_accuracy: 0.4656\\n\",\n",
        "      \"Epoch 3/10\\n\",\n",
        "      \"47/47 [==============================] - 10s 218ms/step - loss: 1.4792 - accuracy: 0.3307 - val_loss: 1.2546 - val_accuracy: 0.4781\\n\",\n",
        "      \"Epoch 4/10\\n\",\n",
        "      \"47/47 [==============================] - 11s 234ms/step - loss: 1.4971 - accuracy: 0.3273 - val_loss: 1.2869 - val_accuracy: 0.4531\\n\",\n",
        "      \"Epoch 5/10\\n\",\n",
        "      \"47/47 [==============================] - 10s 221ms/step - loss: 1.4939 - accuracy: 0.3178 - val_loss: 1.2880 - val_accuracy: 0.4719\\n\",\n",
        "      \"Epoch 6/10\\n\",\n",
        "      \"47/47 [==============================] - 10s 217ms/step - loss: 1.4852 - accuracy: 0.3178 - val_loss: 1.2793 - val_accuracy: 0.4375\\n\",\n",
        "      \"Epoch 7/10\\n\",\n",
        "      \"47/47 [==============================] - 10s 222ms/step - loss: 1.4894 - accuracy: 0.3260 - val_loss: 1.2865 - val_accuracy: 0.4156\\n\",\n",
        "      \"Epoch 8/10\\n\",\n",
        "      \"47/47 [==============================] - 10s 220ms/step - loss: 1.4987 - accuracy: 0.3211 - val_loss: 1.2744 - val_accuracy: 0.4750\\n\",\n",
        "      \"Epoch 9/10\\n\",\n",
        "      \"47/47 [==============================] - 11s 224ms/step - loss: 1.4952 - accuracy: 0.3220 - val_loss: 1.3020 - val_accuracy: 0.4156\\n\",\n",
        "      \"Epoch 10/10\\n\",\n",
        "      \"47/47 [==============================] - 11s 223ms/step - loss: 1.4679 - accuracy: 0.3391 - val_loss: 1.2756 - val_accuracy: 0.4156\\n\"\n",
        "     ]\n",
        "    },\n",
        "    {\n",
        "     \"data\": {\n",
        "      \"text/plain\": [\n",
        "       \"<keras.callbacks.History at 0x7fec605ddee0>\"\n",
        "      ]\n",
        "     },\n",
        "     \"execution_count\": 45,\n",
        "     \"metadata\": {},\n",
        "     \"output_type\": \"execute_result\"\n",
        "    }\n",
        "   ],\n",
        "   \"source\": [\n",
        "    \"model.fit_generator(x_train,steps_per_epoch = 47 ,epochs = 10,validation_data = x_test,validation_steps = 10)\\n\",\n",
        "    \"#steps_per_epoch = no of train images/batch size\\n\",\n",
        "    \"#validation_steps = no of test images/batch size\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 46,\n",
        "   \"metadata\": {\n",
        "    \"id\": \"5nrwRs8k5rSf\"\n",
        "   },\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"model.save(\\\"nutrition.h5\\\")\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 47,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [\n",
        "    {\n",
        "     \"name\": \"stdout\",\n",
        "     \"output_type\": \"stream\",\n",
        "     \"text\": [\n",
        "      \"nutrition.h5\\r\\n\"\n",
        "     ]\n",
        "    }\n",
        "   ],\n",
        "   \"source\": [\n",
        "    \"!tar -zcvf image-classification-model_new.tgz nutrition.h5\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 48,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [\n",
        "    {\n",
        "     \"name\": \"stdout\",\n",
        "     \"output_type\": \"stream\",\n",
        "     \"text\": [\n",
        "      \"\\u001b[0m\\u001b[01;34mDataset\\u001b[0m/\\r\\n\",\n",
        "      \"image-classification-model_new.tgz\\r\\n\",\n",
        "      \"nutrition.h5\\r\\n\"\n",
        "     ]\n",
        "    }\n",
        "   ],\n",
        "   \"source\": [\n",
        "    \"ls -1\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 49,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [\n",
        "    {\n",
        "     \"name\": \"stdout\",\n",
        "     \"output_type\": \"stream\",\n",
        "     \"text\": [\n",
        "      \"Collecting watson-machine-learning-client\\n\",\n",
        "      \"  Downloading watson_machine_learning_client-1.0.391-py3-none-any.whl (538 kB)\\n\",\n",
        "      \"\\u001b[K     |████████████████████████████████| 538 kB 20.1 MB/s eta 0:00:01\\n\",\n",
        "      \"\\u001b[?25hRequirement already satisfied: ibm-cos-sdk in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (2.11.0)\\n\",\n",
        "      \"Requirement already satisfied: certifi in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (2022.9.24)\\n\",\n",
        "      \"Requirement already satisfied: tabulate in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (0.8.9)\\n\",\n",
        "      \"Requirement already satisfied: requests in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (2.26.0)\\n\",\n",
        "      \"Requirement already satisfied: lomond in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (0.3.3)\\n\",\n",
        "      \"Requirement already satisfied: tqdm in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (4.62.3)\\n\",\n",
        "      \"Requirement already satisfied: boto3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (1.18.21)\\n\",\n",
        "      \"Requirement already satisfied: urllib3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (1.26.7)\\n\",\n",
        "      \"Requirement already satisfied: pandas in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (1.3.4)\\n\",\n",
        "      \"Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from boto3->watson-machine-learning-client) (0.5.0)\\n\",\n",
        "      \"Requirement already satisfied: botocore<1.22.0,>=1.21.21 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from boto3->watson-machine-learning-client) (1.21.41)\\n\",\n",
        "      \"Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from boto3->watson-machine-learning-client) (0.10.0)\\n\",\n",
        "      \"Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from botocore<1.22.0,>=1.21.21->boto3->watson-machine-learning-client) (2.8.2)\\n\",\n",
        "      \"Requirement already satisfied: six>=1.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.22.0,>=1.21.21->boto3->watson-machine-learning-client) (1.15.0)\\n\",\n",
        "      \"Requirement already satisfied: ibm-cos-sdk-s3transfer==2.11.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm-cos-sdk->watson-machine-learning-client) (2.11.0)\\n\",\n",
        "      \"Requirement already satisfied: ibm-cos-sdk-core==2.11.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm-cos-sdk->watson-machine-learning-client) (2.11.0)\\n\",\n",
        "      \"Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests->watson-machine-learning-client) (3.3)\\n\",\n",
        "      \"Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests->watson-machine-learning-client) (2.0.4)\\n\",\n",
        "      \"Requirement already satisfied: pytz>=2017.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from pandas->watson-machine-learning-client) (2021.3)\\n\",\n",
        "      \"Requirement already satisfied: numpy>=1.17.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from pandas->watson-machine-learning-client) (1.20.3)\\n\",\n",
        "      \"Installing collected packages: watson-machine-learning-client\\n\",\n",
        "      \"Successfully installed watson-machine-learning-client-1.0.391\\n\"\n",
        "     ]\n",
        "    }\n",
        "   ],\n",
        "   \"source\": [\n",
        "    \"!pip install watson-machine-learning-client\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 50,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"from ibm_watson_machine_learning import APIClient\\n\",\n",
        "    \"wml_credentials={\\n\",\n",
        "    \"    \\\"url\\\":\\\"https://us-south.ml.cloud.ibm.com\\\",\\n\",\n",
        "    \"    \\\"apikey\\\":\\\"BPFGcOrCf3sroRy3uKOPGozsmIL-5oVDv4A_lru2IpMS\\\"\\n\",\n",
        "    \"    \\n\",\n",
        "    \"}\\n\",\n",
        "    \"\\n\",\n",
        "    \"client=APIClient(wml_credentials)\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 51,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [\n",
        "    {\n",
        "     \"data\": {\n",
        "      \"text/plain\": [\n",
        "       \"<ibm_watson_machine_learning.client.APIClient at 0x7fec60578040>\"\n",
        "      ]\n",
        "     },\n",
        "     \"execution_count\": 51,\n",
        "     \"metadata\": {},\n",
        "     \"output_type\": \"execute_result\"\n",
        "    }\n",
        "   ],\n",
        "   \"source\": [\n",
        "    \"client\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 52,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \" def guid_from_space_name(client, space_name):\\n\",\n",
        "    \"     space=client.spaces.get_details()\\n\",\n",
        "    \"     #print(space)\\n\",\n",
        "    \"     return(next(item for item in space['resources'] if item['entity']['name']== space_name)['metadata']['id'])\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 53,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [\n",
        "    {\n",
        "     \"name\": \"stdout\",\n",
        "     \"output_type\": \"stream\",\n",
        "     \"text\": [\n",
        "      \"Space UID =ba02adea-7e10-4237-81e7-eaf084fe4102\\n\"\n",
        "     ]\n",
        "    }\n",
        "   ],\n",
        "   \"source\": [\n",
        "    \"space_uid=guid_from_space_name(client,'imageclassification') #imageclassification is the deployment space name\\n\",\n",
        "    \"print(\\\"Space UID =\\\"+space_uid)\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 54,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [\n",
        "    {\n",
        "     \"data\": {\n",
        "      \"text/plain\": [\n",
        "       \"'SUCCESS'\"\n",
        "      ]\n",
        "     },\n",
        "     \"execution_count\": 54,\n",
        "     \"metadata\": {},\n",
        "     \"output_type\": \"execute_result\"\n",
        "    }\n",
        "   ],\n",
        "   \"source\": [\n",
        "    \"client.set.default_space(space_uid)\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 55,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [\n",
        "    {\n",
        "     \"name\": \"stdout\",\n",
        "     \"output_type\": \"stream\",\n",
        "     \"text\": [\n",
        "      \"-----------------------------  ------------------------------------  ----\\n\",\n",
        "      \"NAME                           ASSET_ID                              TYPE\\n\",\n",
        "      \"default_py3.6                  0062b8c9-8b7d-44a0-a9b9-46c416adcbd9  base\\n\",\n",
        "      \"kernel-spark3.2-scala2.12      020d69ce-7ac1-5e68-ac1a-31189867356a  base\\n\",\n",
        "      \"pytorch-onnx_1.3-py3.7-edt     069ea134-3346-5748-b513-49120e15d288  base\\n\",\n",
        "      \"scikit-learn_0.20-py3.6        09c5a1d0-9c1e-4473-a344-eb7b665ff687  base\\n\",\n",
        "      \"spark-mllib_3.0-scala_2.12     09f4cff0-90a7-5899-b9ed-1ef348aebdee  base\\n\",\n",
        "      \"pytorch-onnx_rt22.1-py3.9      0b848dd4-e681-5599-be41-b5f6fccc6471  base\\n\",\n",
        "      \"ai-function_0.1-py3.6          0cdb0f1e-5376-4f4d-92dd-da3b69aa9bda  base\\n\",\n",
        "      \"shiny-r3.6                     0e6e79df-875e-4f24-8ae9-62dcc2148306  base\\n\",\n",
        "      \"tensorflow_2.4-py3.7-horovod   1092590a-307d-563d-9b62-4eb7d64b3f22  base\\n\",\n",
        "      \"pytorch_1.1-py3.6              10ac12d6-6b30-4ccd-8392-3e922c096a92  base\\n\",\n",
        "      \"tensorflow_1.15-py3.6-ddl      111e41b3-de2d-5422-a4d6-bf776828c4b7  base\\n\",\n",
        "      \"runtime-22.1-py3.9             12b83a17-24d8-5082-900f-0ab31fbfd3cb  base\\n\",\n",
        "      \"scikit-learn_0.22-py3.6        154010fa-5b3b-4ac1-82af-4d5ee5abbc85  base\\n\",\n",
        "      \"default_r3.6                   1b70aec3-ab34-4b87-8aa0-a4a3c8296a36  base\\n\",\n",
        "      \"pytorch-onnx_1.3-py3.6         1bc6029a-cc97-56da-b8e0-39c3880dbbe7  base\\n\",\n",
        "      \"kernel-spark3.3-r3.6           1c9e5454-f216-59dd-a20e-474a5cdf5988  base\\n\",\n",
        "      \"pytorch-onnx_rt22.1-py3.9-edt  1d362186-7ad5-5b59-8b6c-9d0880bde37f  base\\n\",\n",
        "      \"tensorflow_2.1-py3.6           1eb25b84-d6ed-5dde-b6a5-3fbdf1665666  base\\n\",\n",
        "      \"spark-mllib_3.2                20047f72-0a98-58c7-9ff5-a77b012eb8f5  base\\n\",\n",
        "      \"tensorflow_2.4-py3.8-horovod   217c16f6-178f-56bf-824a-b19f20564c49  base\\n\",\n",
        "      \"runtime-22.1-py3.9-cuda        26215f05-08c3-5a41-a1b0-da66306ce658  base\\n\",\n",
        "      \"do_py3.8                       295addb5-9ef9-547e-9bf4-92ae3563e720  base\\n\",\n",
        "      \"autoai-ts_3.8-py3.8            2aa0c932-798f-5ae9-abd6-15e0c2402fb5  base\\n\",\n",
        "      \"tensorflow_1.15-py3.6          2b73a275-7cbf-420b-a912-eae7f436e0bc  base\\n\",\n",
        "      \"kernel-spark3.3-py3.9          2b7961e2-e3b1-5a8c-a491-482c8368839a  base\\n\",\n",
        "      \"pytorch_1.2-py3.6              2c8ef57d-2687-4b7d-acce-01f94976dac1  base\\n\",\n",
        "      \"spark-mllib_2.3                2e51f700-bca0-4b0d-88dc-5c6791338875  base\\n\",\n",
        "      \"pytorch-onnx_1.1-py3.6-edt     32983cea-3f32-4400-8965-dde874a8d67e  base\\n\",\n",
        "      \"spark-mllib_3.0-py37           36507ebe-8770-55ba-ab2a-eafe787600e9  base\\n\",\n",
        "      \"spark-mllib_2.4                390d21f8-e58b-4fac-9c55-d7ceda621326  base\\n\",\n",
        "      \"xgboost_0.82-py3.6             39e31acd-5f30-41dc-ae44-60233c80306e  base\\n\",\n",
        "      \"pytorch-onnx_1.2-py3.6-edt     40589d0e-7019-4e28-8daa-fb03b6f4fe12  base\\n\",\n",
        "      \"default_r36py38                41c247d3-45f8-5a71-b065-8580229facf0  base\\n\",\n",
        "      \"autoai-ts_rt22.1-py3.9         4269d26e-07ba-5d40-8f66-2d495b0c71f7  base\\n\",\n",
        "      \"autoai-obm_3.0                 42b92e18-d9ab-567f-988a-4240ba1ed5f7  base\\n\",\n",
        "      \"pmml-3.0_4.3                   493bcb95-16f1-5bc5-bee8-81b8af80e9c7  base\\n\",\n",
        "      \"spark-mllib_2.4-r_3.6          49403dff-92e9-4c87-a3d7-a42d0021c095  base\\n\",\n",
        "      \"xgboost_0.90-py3.6             4ff8d6c2-1343-4c18-85e1-689c965304d3  base\\n\",\n",
        "      \"pytorch-onnx_1.1-py3.6         50f95b2a-bc16-43bb-bc94-b0bed208c60b  base\\n\",\n",
        "      \"autoai-ts_3.9-py3.8            52c57136-80fa-572e-8728-a5e7cbb42cde  base\\n\",\n",
        "      \"spark-mllib_2.4-scala_2.11     55a70f99-7320-4be5-9fb9-9edb5a443af5  base\\n\",\n",
        "      \"spark-mllib_3.0                5c1b0ca2-4977-5c2e-9439-ffd44ea8ffe9  base\\n\",\n",
        "      \"autoai-obm_2.0                 5c2e37fa-80b8-5e77-840f-d912469614ee  base\\n\",\n",
        "      \"spss-modeler_18.1              5c3cad7e-507f-4b2a-a9a3-ab53a21dee8b  base\\n\",\n",
        "      \"cuda-py3.8                     5d3232bf-c86b-5df4-a2cd-7bb870a1cd4e  base\\n\",\n",
        "      \"autoai-kb_3.1-py3.7            632d4b22-10aa-5180-88f0-f52dfb6444d7  base\\n\",\n",
        "      \"pytorch-onnx_1.7-py3.8         634d3cdc-b562-5bf9-a2d4-ea90a478456b  base\\n\",\n",
        "      \"spark-mllib_2.3-r_3.6          6586b9e3-ccd6-4f92-900f-0f8cb2bd6f0c  base\\n\",\n",
        "      \"tensorflow_2.4-py3.7           65e171d7-72d1-55d9-8ebb-f813d620c9bb  base\\n\",\n",
        "      \"spss-modeler_18.2              687eddc9-028a-4117-b9dd-e57b36f1efa5  base\\n\",\n",
        "      \"-----------------------------  ------------------------------------  ----\\n\",\n",
        "      \"Note: Only first 50 records were displayed. To display more use 'limit' parameter.\\n\"\n",
        "     ]\n",
        "    }\n",
        "   ],\n",
        "   \"source\": [\n",
        "    \"client.software_specifications.list()\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 56,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"software_space_uid=client.software_specifications.get_uid_by_name('tensorflow_rt22.1-py3.9')\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 57,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [\n",
        "    {\n",
        "     \"data\": {\n",
        "      \"text/plain\": [\n",
        "       \"'acd9c798-6974-5d2f-a657-ce06e986df4d'\"\n",
        "      ]\n",
        "     },\n",
        "     \"execution_count\": 57,\n",
        "     \"metadata\": {},\n",
        "     \"output_type\": \"execute_result\"\n",
        "    }\n",
        "   ],\n",
        "   \"source\": [\n",
        "    \"software_space_uid\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 58,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"model_details=client.repository.store_model(model='image-classification-model_new.tgz',meta_props={\\n\",\n",
        "    \"    client.repository.ModelMetaNames.NAME:\\\"CNN\\\",\\n\",\n",
        "    \"    client.repository.ModelMetaNames.TYPE:'tensorflow_2.7',\\n\",\n",
        "    \"    client.repository.ModelMetaNames.SOFTWARE_SPEC_UID:software_space_uid}\\n\",\n",
        "    \"                                             )\\n\",\n",
        "    \"model_id = client.repository.get_model_id(model_details)\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 59,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [\n",
        "    {\n",
        "     \"data\": {\n",
        "      \"text/plain\": [\n",
        "       \"'f3e12114-24f4-4bae-9d60-2897d27e7ce6'\"\n",
        "      ]\n",
        "     },\n",
        "     \"execution_count\": 59,\n",
        "     \"metadata\": {},\n",
        "     \"output_type\": \"execute_result\"\n",
        "    }\n",
        "   ],\n",
        "   \"source\": [\n",
        "    \"model_id\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 60,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [\n",
        "    {\n",
        "     \"name\": \"stdout\",\n",
        "     \"output_type\": \"stream\",\n",
        "     \"text\": [\n",
        "      \"Successfully saved model content to file: 'my_model.tar.gz'\\n\"\n",
        "     ]\n",
        "    },\n",
        "    {\n",
        "     \"data\": {\n",
        "      \"text/plain\": [\n",
        "       \"'/home/wsuser/work/my_model.tar.gz'\"\n",
        "      ]\n",
        "     },\n",
        "     \"execution_count\": 60,\n",
        "     \"metadata\": {},\n",
        "     \"output_type\": \"execute_result\"\n",
        "    }\n",
        "   ],\n",
        "   \"source\": [\n",
        "    \"client.repository.download(model_id, 'my_model.tar.gz')\"\n",
        "   ]\n",
        "  }\n",
        " ],\n",
        " \"metadata\": {\n",
        "  \"colab\": {\n",
        "   \"provenance\": []\n",
        "  },\n",
        "  \"kernelspec\": {\n",
        "   \"display_name\": \"Python 3.9\",\n",
        "   \"language\": \"python\",\n",
        "   \"name\": \"python3\"\n",
        "  },\n",
        "  \"language_info\": {\n",
        "   \"codemirror_mode\": {\n",
        "    \"name\": \"ipython\",\n",
        "    \"version\": 3\n",
        "   },\n",
        "   \"file_extension\": \".py\",\n",
        "   \"mimetype\": \"text/x-python\",\n",
        "   \"name\": \"python\",\n",
        "   \"nbconvert_exporter\": \"python\",\n",
        "   \"pygments_lexer\": \"ipython3\",\n",
        "   \"version\": \"3.9.13\"\n",
        "  }\n",
        " },\n",
        " \"nbformat\": 4,\n",
        " \"nbformat_minor\": 1\n",
        "}"
      ]
    }
  ]
}